{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1BFg3Z87hRxmiWr8jmGOhnElZt3iD0IaA",
      "authorship_tag": "ABX9TyOcWZPwyjP1ZKh1s4/lktVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nekoiii/ML_Practices_colab/blob/main/Lora_test_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sd-scripts github: https://github.com/kohya-ss/sd-scripts\n",
        "\n",
        "Reference article：\n",
        "· https://tkstock.site/2023/05/19/googlecolab-stablediffusion-lora-finetuning/#i-7\n",
        "\n",
        "· https://www.ipentec.com/document/software-stable-diffusion-lora-learn#section_12\n",
        "\n"
      ],
      "metadata": {
        "id": "3oxQHizixLE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aShyASAL7AIv",
        "outputId": "c5003a51-c30b-422d-cfdd-3d99fef680d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_4lzMp7FOB",
        "outputId": "cfea8c54-5aa6-428c-b9d9-db46033579e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kohya-ss/sd-scripts /content/drive/MyDrive/StableDifussion/sd-scripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIK3xuD87MXj",
        "outputId": "cb0ffbd4-419f-4e6a-949f-9bc2054aab1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/MyDrive/StableDifussion/sd-scripts'...\n",
            "remote: Enumerating objects: 3070, done.\u001b[K\n",
            "remote: Counting objects: 100% (1483/1483), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 3070 (delta 1367), reused 1368 (delta 1320), pack-reused 1587\u001b[K\n",
            "Receiving objects: 100% (3070/3070), 3.45 MiB | 16.82 MiB/s, done.\n",
            "Resolving deltas: 100% (2122/2122), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#According to the sd-scripts github documentation, we should install PyTorch before install requirements.txt \n",
        "#because the versions of it depends on your environment and requirements.txt does not contain requirements for PyTorch.\n",
        "\n",
        "%cd /content/drive/MyDrive/StableDifussion/sd-scripts\n",
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install  --upgrade -r requirements.txt\n",
        "#!pip install -U --pre triton\n",
        "!pip install xformers==0.0.16rc425\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iIbzKkG67MU7",
        "outputId": "ee55e18e-779d-4641-e30e-341192b56716"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp310-cp310-linux_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu117) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (3.4)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu117 torchvision-0.14.1+cu117\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.15.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1 (from -r requirements.txt (line 3))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m64.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations==1.3.0 (from -r requirements.txt (line 4))\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.7.0.68 (from -r requirements.txt (line 5))\n",
            "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.0 (from -r requirements.txt (line 6))\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers[torch]==0.10.2 (from -r requirements.txt (line 7))\n",
            "  Downloading diffusers-0.10.2-py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.35.0 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.35.0-py3-none-any.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard==2.10.1 (from -r requirements.txt (line 10))\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors==0.2.6 (from -r requirements.txt (line 11))\n",
            "  Downloading safetensors-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.2.2)\n",
            "Collecting easygui==0.98.3 (from -r requirements.txt (line 14))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Collecting voluptuous==0.13.1 (from -r requirements.txt (line 16))\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Collecting requests==2.28.2 (from -r requirements.txt (line 18))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.6.12 (from -r requirements.txt (line 19))\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale==0.4.13 (from -r requirements.txt (line 20))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow==2.10.1 (from -r requirements.txt (line 23))\n",
            "  Downloading tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.13.3 (from -r requirements.txt (line 24))\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (1.13.1+cu117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.0->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 3)) (0.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (4.7.0.72)\n",
            "Collecting importlib-metadata (from diffusers[torch]==0.10.2->-r requirements.txt (line 7))\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.5.0)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (3.4.3)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (67.7.2)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (0.40.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (4.3.3)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (1.5.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2022.12.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12->-r requirements.txt (line 19)) (0.14.1+cu117)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.8.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.14.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 13)) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 13)) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 13)) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (3.15.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (3.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Building wheels for collected packages: fairscale, library\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=c1b2c43ff8866b4d278a767f168fc810d40d0664082cc5c45b72a233a2e00837\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for library: filename=library-0.0.0-py3-none-any.whl size=83355 sha256=5be89c5707b18f7495d9f65877d4f7fae792662b7855ca355c224fa4979d1c83\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/56/d6/9784fb87ab54c1caf203d81a063041071e9705a7c313678e4d\n",
            "Successfully built fairscale library\n",
            "Installing collected packages: voluptuous, tokenizers, safetensors, library, keras, easygui, bitsandbytes, tensorflow-estimator, tensorboard-data-server, requests, protobuf, opencv-python, multidict, lightning-utilities, keras-preprocessing, importlib-metadata, ftfy, frozenlist, einops, async-timeout, yarl, torchmetrics, huggingface-hub, fairscale, aiosignal, accelerate, transformers, timm, google-auth-oauthlib, diffusers, aiohttp, tensorboard, albumentations, tensorflow, pytorch-lightning\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.7.0.72\n",
            "    Uninstalling opencv-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-4.7.0.72\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.15.0 aiohttp-3.8.4 aiosignal-1.3.1 albumentations-1.3.0 async-timeout-4.0.2 bitsandbytes-0.35.0 diffusers-0.10.2 easygui-0.98.3 einops-0.6.0 fairscale-0.4.13 frozenlist-1.3.3 ftfy-6.1.1 google-auth-oauthlib-0.4.6 huggingface-hub-0.13.3 importlib-metadata-6.6.0 keras-2.10.0 keras-preprocessing-1.1.2 library-0.0.0 lightning-utilities-0.8.0 multidict-6.0.4 opencv-python-4.7.0.68 protobuf-3.19.6 pytorch-lightning-1.9.0 requests-2.28.2 safetensors-0.2.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 timm-0.6.12 tokenizers-0.13.3 torchmetrics-0.11.4 transformers-4.26.0 voluptuous-0.13.1 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xformers==0.0.16rc425\n",
            "  Downloading xformers-0.0.16rc425-cp310-cp310-manylinux2014_x86_64.whl (50.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (1.22.4)\n",
            "Collecting pyre-extensions==0.0.23 (from xformers==0.0.16rc425)\n",
            "  Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (1.13.1+cu117)\n",
            "Collecting typing-inspect (from pyre-extensions==0.0.23->xformers==0.0.16rc425)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.23->xformers==0.0.16rc425) (4.5.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions==0.0.23->xformers==0.0.16rc425)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, xformers\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.23 typing-inspect-0.9.0 xformers-0.0.16rc425\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change some config (Some user reports [ValueError: fp16 mixed precision requires a GPU] is occurred in training )\n",
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UPKQip-IXW",
        "outputId": "ef5bd654-7c70-4d5a-a430-b726c81a4536"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-13 07:45:55.823076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 07:45:56.024758: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 07:45:56.858839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 07:45:56.858966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 07:45:56.858983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy training images folder\n",
        "training_data_path='/content/training_data'\n",
        "\n",
        "%cp -r /content/drive/MyDrive/datasets/imgs/resized_canbright_imgs_1_partial '{training_data_path}'"
      ],
      "metadata": {
        "id": "xtp4ZN6f-IVD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate captions and tags for each image.\n",
        "%cd /content/drive/MyDrive/StableDifussion/sd-scripts\n",
        "\n",
        "!python finetune/make_captions.py --batch_size 8 '{training_data_path}'\n",
        "!python finetune/tag_images_by_wd14_tagger.py --batch_size 4 '{training_data_path}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9duevbKj-IRw",
        "outputId": "b0f2b4d7-d388-4783-caf8-7e19bf53bee6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "2023-06-13 08:43:16.383163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:43:16.580687: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 08:43:17.454523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:43:17.454610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:43:17.454625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Current Working Directory is:  /content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "load images from /content/training_data\n",
            "found 12 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "100% 12/12 [00:03<00:00,  3.36it/s]\n",
            "done!\n",
            "2023-06-13 08:43:40.900550: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:43:41.063972: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 08:43:41.863073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-06-13 08:43:41.863158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-06-13 08:43:41.863169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "using existing wd14 tagger model\n",
            "2023-06-13 08:43:46.165764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:46.172065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:46.172299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:46.172686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:43:46.173291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:46.173499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:46.173669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:47.031134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:47.031414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:47.031629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-13 08:43:47.031759: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-06-13 08:43:47.031802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "found 12 images.\n",
            "  0% 0/12 [00:00<?, ?it/s]2023-06-13 08:44:01.078252: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
            "100% 12/12 [00:03<00:00,  3.59it/s]\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merges captions with metadata and outputs the result in meta_cap.json.\n",
        "# Merges Data Description (DD) tags with metadata from the previous step and generates a new file meta_cap_dd.json.\n",
        "# Cleans and preprocesses the captions and tags from the previous step and generates a cleaned version in meta_clean.json.\n",
        "\n",
        "!python finetune/merge_captions_to_metadata.py '{training_data_path}' meta_cap.json\n",
        "!python finetune/merge_dd_tags_to_metadata.py '{training_data_path}' --in_json meta_cap.json meta_cap_dd.json\n",
        "!python finetune/clean_captions_and_tags.py meta_cap_dd.json meta_clean.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTqoRfiH_89C",
        "outputId": "d838e732-82be-4929-e244-1a21afae8e6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-13 08:44:07.410475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:44:07.608010: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 08:44:08.462649: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:44:08.462751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:44:08.462770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "found 12 images.\n",
            "loading existing metadata: meta_cap.json\n",
            "captions for existing images will be overwritten / 既存の画像のキャプションは上書きされます\n",
            "merge caption texts to metadata json.\n",
            "100% 12/12 [00:00<00:00, 24552.02it/s]\n",
            "writing metadata: meta_cap.json\n",
            "done!\n",
            "2023-06-13 08:44:13.886089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:44:14.071306: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 08:44:14.859839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:44:14.859925: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 08:44:14.859936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "found 12 images.\n",
            "loading existing metadata: meta_cap.json\n",
            "tags data for existing images will be overwritten / 既存の画像のタグは上書きされます\n",
            "merge tags to metadata json.\n",
            "100% 12/12 [00:00<00:00, 22359.68it/s]\n",
            "writing metadata: meta_cap_dd.json\n",
            "done!\n",
            "loading existing metadata: meta_cap_dd.json\n",
            "cleaning captions and tags.\n",
            "100% 12/12 [00:00<00:00, 4605.33it/s]\n",
            "writing metadata: meta_clean.json\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune/prepare_buckets_latents.py \\\n",
        "'{training_data_path}' meta_clean.json meta_lat.json \\\n",
        "/content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt \\\n",
        "--batch_size 4 \\\n",
        "--max_resolution 512,512 \\\n",
        "--mixed_precision no"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpeipJV2_86a",
        "outputId": "5ead0bd7-79b7-4af1-f900-02abcf42ff13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-13 08:44:20.603441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 08:44:20.800835: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 08:44:21.616483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-06-13 08:44:21.616610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-06-13 08:44:21.616629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "found 12 images.\n",
            "loading existing metadata: meta_clean.json\n",
            "load VAE: /content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt\n",
            "100% 12/12 [00:03<00:00,  3.03it/s]\n",
            "bucket 0 (512, 512): 12\n",
            "mean ar error: 0.0\n",
            "writing metadata: meta_lat.json\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgGDs2bG1K-",
        "outputId": "1308b979-2d58-49c8-aa0d-e347ec6a06c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sd-scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch  \\\n",
        "--num_cpu_threads_per_process 1 \\\n",
        "train_network.py \\\n",
        "--pretrained_model_name_or_path=/content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt \\\n",
        "--in_json modified_meta_lat.json \\\n",
        "--train_data_dir='{training_data_path}' \\\n",
        "--output_dir=output_models \\\n",
        "--shuffle_caption \\\n",
        "--train_batch_size=1 \\\n",
        "--learning_rate=1e-4 \\\n",
        "--max_train_steps=5000 \\\n",
        "--use_8bit_adam \\\n",
        "--xformers --gradient_checkpointing \\\n",
        "--mixed_precision=fp16 \\\n",
        "--save_every_n_epochs=10 \\\n",
        "--save_precision=fp16 \\\n",
        "--network_module=networks.lora\\\n",
        "--training_comment=\"cb_satoo\" \\\n",
        "#--save_model_as= safetensors\n",
        "#--save_model_as= pt \n",
        "#--output_name=satoo_with_descriptions \\\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsVo9HXx7MLa",
        "outputId": "32abcbf6-8f19-42bb-bf54-09a5395a9389"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-13 10:26:14.686541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 10:26:14.875144: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 10:26:15.645136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:26:15.645216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:26:15.645228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-06-13 10:26:18.481995: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 10:26:19.314204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:26:19.314319: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:26:19.314341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "prepare tokenizer\n",
            "Training with captions.\n",
            "loading existing metadata: modified_meta_lat.json\n",
            "metadata has bucket info, enable bucketing / メタデータにbucket情報があるためbucketを有効にします\n",
            "using bucket info in metadata / メタデータ内のbucket情報を使います\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (None, None)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: None\n",
            "  max_bucket_reso: None\n",
            "  bucket_reso_steps: None\n",
            "  bucket_no_upscale: None\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/training_data\"\n",
            "    image_count: 12\n",
            "    num_repeats: 1\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    metadata_file: modified_meta_lat.json\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 12/12 [00:00<00:00, 276547.52it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (512, 512), count: 12\n",
            "mean ar error (without repeats): 0.0\n",
            "preparing accelerator\n",
            "Using accelerator 0.15.0 or above.\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint: /content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "CrossAttention.forward has been replaced to enable xformers.\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 4, alpha: 1\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "preparing optimizer, data loader etc.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "use 8-bit AdamW optimizer | {}\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 12\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 12\n",
            "  num epochs / epoch数: 417\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 5000\n",
            "steps:   0% 0/5000 [00:00<?, ?it/s]\n",
            "epoch 1/417\n",
            "steps:   0% 12/5000 [00:08<55:47,  1.49it/s, loss=0.115]\n",
            "epoch 2/417\n",
            "steps:   0% 24/5000 [00:14<49:49,  1.66it/s, loss=0.0746]\n",
            "epoch 3/417\n",
            "steps:   1% 36/5000 [00:20<47:19,  1.75it/s, loss=0.109]\n",
            "epoch 4/417\n",
            "steps:   1% 48/5000 [00:27<46:27,  1.78it/s, loss=0.0632]\n",
            "epoch 5/417\n",
            "steps:   1% 60/5000 [00:33<45:39,  1.80it/s, loss=0.0859]\n",
            "epoch 6/417\n",
            "steps:   1% 72/5000 [00:39<45:00,  1.82it/s, loss=0.147]\n",
            "epoch 7/417\n",
            "steps:   2% 84/5000 [00:45<44:50,  1.83it/s, loss=0.121]\n",
            "epoch 8/417\n",
            "steps:   2% 96/5000 [00:52<44:23,  1.84it/s, loss=0.0557]\n",
            "epoch 9/417\n",
            "steps:   2% 108/5000 [00:58<44:05,  1.85it/s, loss=0.0852]\n",
            "epoch 10/417\n",
            "steps:   2% 120/5000 [01:04<43:59,  1.85it/s, loss=0.0954]\n",
            "saving checkpoint: output_models/epoch-000010.safetensors\n",
            "\n",
            "epoch 11/417\n",
            "steps:   3% 132/5000 [01:11<43:50,  1.85it/s, loss=0.0936]\n",
            "epoch 12/417\n",
            "steps:   3% 144/5000 [01:17<43:38,  1.85it/s, loss=0.0976]\n",
            "epoch 13/417\n",
            "steps:   3% 156/5000 [01:24<43:32,  1.85it/s, loss=0.0757]\n",
            "epoch 14/417\n",
            "steps:   3% 168/5000 [01:30<43:20,  1.86it/s, loss=0.0718]\n",
            "epoch 15/417\n",
            "steps:   4% 180/5000 [01:36<43:13,  1.86it/s, loss=0.0876]\n",
            "epoch 16/417\n",
            "steps:   4% 192/5000 [01:43<43:07,  1.86it/s, loss=0.104] \n",
            "epoch 17/417\n",
            "steps:   4% 204/5000 [01:49<43:02,  1.86it/s, loss=0.1]  \n",
            "epoch 18/417\n",
            "steps:   4% 216/5000 [01:56<43:02,  1.85it/s, loss=0.0924]\n",
            "epoch 19/417\n",
            "steps:   5% 228/5000 [02:03<42:55,  1.85it/s, loss=0.0366]\n",
            "epoch 20/417\n",
            "steps:   5% 240/5000 [02:09<42:53,  1.85it/s, loss=0.058] \n",
            "saving checkpoint: output_models/epoch-000020.safetensors\n",
            "\n",
            "epoch 21/417\n",
            "steps:   5% 252/5000 [02:16<42:53,  1.85it/s, loss=0.0618]\n",
            "epoch 22/417\n",
            "steps:   5% 264/5000 [02:23<42:45,  1.85it/s, loss=0.0823]\n",
            "epoch 23/417\n",
            "steps:   6% 276/5000 [02:29<42:42,  1.84it/s, loss=0.0583]\n",
            "epoch 24/417\n",
            "steps:   6% 288/5000 [02:36<42:36,  1.84it/s, loss=0.0726]\n",
            "epoch 25/417\n",
            "steps:   6% 300/5000 [02:42<42:29,  1.84it/s, loss=0.117]\n",
            "epoch 26/417\n",
            "steps:   6% 312/5000 [02:49<42:28,  1.84it/s, loss=0.104]\n",
            "epoch 27/417\n",
            "steps:   6% 324/5000 [02:55<42:19,  1.84it/s, loss=0.0683]\n",
            "epoch 28/417\n",
            "steps:   7% 336/5000 [03:02<42:14,  1.84it/s, loss=0.102]\n",
            "epoch 29/417\n",
            "steps:   7% 348/5000 [03:09<42:09,  1.84it/s, loss=0.0578]\n",
            "epoch 30/417\n",
            "steps:   7% 360/5000 [03:15<42:02,  1.84it/s, loss=0.1]  \n",
            "saving checkpoint: output_models/epoch-000030.safetensors\n",
            "\n",
            "epoch 31/417\n",
            "steps:   7% 372/5000 [03:22<42:00,  1.84it/s, loss=0.0783]\n",
            "epoch 32/417\n",
            "steps:   8% 384/5000 [03:29<41:53,  1.84it/s, loss=0.0654]\n",
            "epoch 33/417\n",
            "steps:   8% 396/5000 [03:35<41:45,  1.84it/s, loss=0.0555]\n",
            "epoch 34/417\n",
            "steps:   8% 408/5000 [03:42<41:42,  1.83it/s, loss=0.0678]\n",
            "epoch 35/417\n",
            "steps:   8% 420/5000 [03:48<41:35,  1.84it/s, loss=0.118]\n",
            "epoch 36/417\n",
            "steps:   9% 432/5000 [03:55<41:29,  1.84it/s, loss=0.0833]\n",
            "epoch 37/417\n",
            "steps:   9% 444/5000 [04:01<41:22,  1.84it/s, loss=0.104]\n",
            "epoch 38/417\n",
            "steps:   9% 456/5000 [04:08<41:15,  1.84it/s, loss=0.113]\n",
            "epoch 39/417\n",
            "steps:   9% 468/5000 [04:15<41:11,  1.83it/s, loss=0.0859]\n",
            "epoch 40/417\n",
            "steps:  10% 480/5000 [04:21<41:05,  1.83it/s, loss=0.053] \n",
            "saving checkpoint: output_models/epoch-000040.safetensors\n",
            "\n",
            "epoch 41/417\n",
            "steps:  10% 492/5000 [04:28<41:00,  1.83it/s, loss=0.0604]\n",
            "epoch 42/417\n",
            "steps:  10% 504/5000 [04:35<40:55,  1.83it/s, loss=0.0564]\n",
            "epoch 43/417\n",
            "steps:  10% 516/5000 [04:41<40:48,  1.83it/s, loss=0.0687]\n",
            "epoch 44/417\n",
            "steps:  11% 528/5000 [04:48<40:44,  1.83it/s, loss=0.114]\n",
            "epoch 45/417\n",
            "steps:  11% 540/5000 [04:55<40:39,  1.83it/s, loss=0.0973]\n",
            "epoch 46/417\n",
            "steps:  11% 552/5000 [05:01<40:32,  1.83it/s, loss=0.0826]\n",
            "epoch 47/417\n",
            "steps:  11% 564/5000 [05:09<40:30,  1.83it/s, loss=0.118]\n",
            "epoch 48/417\n",
            "steps:  12% 576/5000 [05:15<40:23,  1.83it/s, loss=0.0523]\n",
            "epoch 49/417\n",
            "steps:  12% 588/5000 [05:22<40:17,  1.82it/s, loss=0.0751]\n",
            "epoch 50/417\n",
            "steps:  12% 600/5000 [05:29<40:12,  1.82it/s, loss=0.0576]\n",
            "saving checkpoint: output_models/epoch-000050.safetensors\n",
            "\n",
            "epoch 51/417\n",
            "steps:  12% 612/5000 [05:35<40:07,  1.82it/s, loss=0.0825]\n",
            "epoch 52/417\n",
            "steps:  12% 624/5000 [05:42<40:02,  1.82it/s, loss=0.0484]\n",
            "epoch 53/417\n",
            "steps:  13% 636/5000 [05:49<39:56,  1.82it/s, loss=0.0803]\n",
            "epoch 54/417\n",
            "steps:  13% 648/5000 [05:55<39:50,  1.82it/s, loss=0.0465]\n",
            "epoch 55/417\n",
            "steps:  13% 660/5000 [06:02<39:46,  1.82it/s, loss=0.0844]\n",
            "epoch 56/417\n",
            "steps:  13% 672/5000 [06:09<39:39,  1.82it/s, loss=0.0738]\n",
            "epoch 57/417\n",
            "steps:  14% 684/5000 [06:16<39:33,  1.82it/s, loss=0.0931]\n",
            "epoch 58/417\n",
            "steps:  14% 696/5000 [06:22<39:28,  1.82it/s, loss=0.0532]\n",
            "epoch 59/417\n",
            "steps:  14% 708/5000 [06:29<39:21,  1.82it/s, loss=0.0429]\n",
            "epoch 60/417\n",
            "steps:  14% 720/5000 [06:36<39:16,  1.82it/s, loss=0.0645]\n",
            "saving checkpoint: output_models/epoch-000060.safetensors\n",
            "\n",
            "epoch 61/417\n",
            "steps:  15% 732/5000 [06:43<39:10,  1.82it/s, loss=0.081]\n",
            "epoch 62/417\n",
            "steps:  15% 744/5000 [06:49<39:04,  1.82it/s, loss=0.0539]\n",
            "epoch 63/417\n",
            "steps:  15% 756/5000 [06:56<38:58,  1.81it/s, loss=0.0745]\n",
            "epoch 64/417\n",
            "steps:  15% 768/5000 [07:03<38:51,  1.82it/s, loss=0.107]\n",
            "epoch 65/417\n",
            "steps:  16% 780/5000 [07:09<38:45,  1.81it/s, loss=0.0783]\n",
            "epoch 66/417\n",
            "steps:  16% 792/5000 [07:16<38:39,  1.81it/s, loss=0.0586]\n",
            "epoch 67/417\n",
            "steps:  16% 804/5000 [07:23<38:32,  1.81it/s, loss=0.0778]\n",
            "epoch 68/417\n",
            "steps:  16% 816/5000 [07:29<38:26,  1.81it/s, loss=0.0485]\n",
            "epoch 69/417\n",
            "steps:  17% 828/5000 [07:36<38:20,  1.81it/s, loss=0.0885]\n",
            "epoch 70/417\n",
            "steps:  17% 840/5000 [07:43<38:13,  1.81it/s, loss=0.0379]\n",
            "saving checkpoint: output_models/epoch-000070.safetensors\n",
            "\n",
            "epoch 71/417\n",
            "steps:  17% 852/5000 [07:50<38:08,  1.81it/s, loss=0.0576]\n",
            "epoch 72/417\n",
            "steps:  17% 864/5000 [07:56<38:01,  1.81it/s, loss=0.106]\n",
            "epoch 73/417\n",
            "steps:  18% 876/5000 [08:03<37:55,  1.81it/s, loss=0.0688]\n",
            "epoch 74/417\n",
            "steps:  18% 888/5000 [08:09<37:48,  1.81it/s, loss=0.0532]\n",
            "epoch 75/417\n",
            "steps:  18% 900/5000 [08:16<37:41,  1.81it/s, loss=0.0457]\n",
            "epoch 76/417\n",
            "steps:  18% 912/5000 [08:23<37:36,  1.81it/s, loss=0.0624]\n",
            "epoch 77/417\n",
            "steps:  18% 924/5000 [08:29<37:29,  1.81it/s, loss=0.0673]\n",
            "epoch 78/417\n",
            "steps:  19% 936/5000 [08:36<37:22,  1.81it/s, loss=0.0692]\n",
            "epoch 79/417\n",
            "steps:  19% 948/5000 [08:43<37:16,  1.81it/s, loss=0.0649]\n",
            "epoch 80/417\n",
            "steps:  19% 960/5000 [08:49<37:09,  1.81it/s, loss=0.0645]\n",
            "saving checkpoint: output_models/epoch-000080.safetensors\n",
            "\n",
            "epoch 81/417\n",
            "steps:  19% 972/5000 [08:56<37:04,  1.81it/s, loss=0.0682]\n",
            "epoch 82/417\n",
            "steps:  20% 984/5000 [09:03<36:57,  1.81it/s, loss=0.0668]\n",
            "epoch 83/417\n",
            "steps:  20% 996/5000 [09:09<36:50,  1.81it/s, loss=0.0872]\n",
            "epoch 84/417\n",
            "steps:  20% 1008/5000 [09:16<36:44,  1.81it/s, loss=0.046] \n",
            "epoch 85/417\n",
            "steps:  20% 1020/5000 [09:23<36:38,  1.81it/s, loss=0.0849]\n",
            "epoch 86/417\n",
            "steps:  21% 1032/5000 [09:30<36:31,  1.81it/s, loss=0.0506]\n",
            "epoch 87/417\n",
            "steps:  21% 1044/5000 [09:36<36:26,  1.81it/s, loss=0.111]\n",
            "epoch 88/417\n",
            "steps:  21% 1056/5000 [09:43<36:19,  1.81it/s, loss=0.0407]\n",
            "epoch 89/417\n",
            "steps:  21% 1068/5000 [09:50<36:12,  1.81it/s, loss=0.106]\n",
            "epoch 90/417\n",
            "steps:  22% 1080/5000 [09:56<36:06,  1.81it/s, loss=0.0574]\n",
            "saving checkpoint: output_models/epoch-000090.safetensors\n",
            "\n",
            "epoch 91/417\n",
            "steps:  22% 1092/5000 [10:03<36:00,  1.81it/s, loss=0.0533]\n",
            "epoch 92/417\n",
            "steps:  22% 1104/5000 [10:10<35:54,  1.81it/s, loss=0.0742]\n",
            "epoch 93/417\n",
            "steps:  22% 1116/5000 [10:16<35:47,  1.81it/s, loss=0.0915]\n",
            "epoch 94/417\n",
            "steps:  23% 1128/5000 [10:23<35:40,  1.81it/s, loss=0.0688]\n",
            "epoch 95/417\n",
            "steps:  23% 1140/5000 [10:30<35:34,  1.81it/s, loss=0.0694]\n",
            "epoch 96/417\n",
            "steps:  23% 1152/5000 [10:36<35:27,  1.81it/s, loss=0.0565]\n",
            "epoch 97/417\n",
            "steps:  23% 1164/5000 [10:43<35:21,  1.81it/s, loss=0.069] \n",
            "epoch 98/417\n",
            "steps:  24% 1176/5000 [10:50<35:14,  1.81it/s, loss=0.0828]\n",
            "epoch 99/417\n",
            "steps:  24% 1188/5000 [10:56<35:08,  1.81it/s, loss=0.0553]\n",
            "epoch 100/417\n",
            "steps:  24% 1200/5000 [11:03<35:02,  1.81it/s, loss=0.0382]\n",
            "saving checkpoint: output_models/epoch-000100.safetensors\n",
            "\n",
            "epoch 101/417\n",
            "steps:  24% 1212/5000 [11:10<34:55,  1.81it/s, loss=0.0806]\n",
            "epoch 102/417\n",
            "steps:  24% 1224/5000 [11:17<34:50,  1.81it/s, loss=0.0312]\n",
            "epoch 103/417\n",
            "steps:  25% 1236/5000 [11:24<34:43,  1.81it/s, loss=0.0564]\n",
            "epoch 104/417\n",
            "steps:  25% 1248/5000 [11:30<34:36,  1.81it/s, loss=0.0963]\n",
            "epoch 105/417\n",
            "steps:  25% 1260/5000 [11:37<34:30,  1.81it/s, loss=0.0361]\n",
            "epoch 106/417\n",
            "steps:  25% 1272/5000 [11:43<34:23,  1.81it/s, loss=0.092] \n",
            "epoch 107/417\n",
            "steps:  26% 1284/5000 [11:50<34:16,  1.81it/s, loss=0.117]\n",
            "epoch 108/417\n",
            "steps:  26% 1296/5000 [11:57<34:10,  1.81it/s, loss=0.0658]\n",
            "epoch 109/417\n",
            "steps:  26% 1308/5000 [12:03<34:03,  1.81it/s, loss=0.0316]\n",
            "epoch 110/417\n",
            "steps:  26% 1320/5000 [12:10<33:56,  1.81it/s, loss=0.0656]\n",
            "saving checkpoint: output_models/epoch-000110.safetensors\n",
            "\n",
            "epoch 111/417\n",
            "steps:  27% 1332/5000 [12:17<33:50,  1.81it/s, loss=0.0796]\n",
            "epoch 112/417\n",
            "steps:  27% 1344/5000 [12:23<33:43,  1.81it/s, loss=0.056] \n",
            "epoch 113/417\n",
            "steps:  27% 1356/5000 [12:30<33:36,  1.81it/s, loss=0.0837]\n",
            "epoch 114/417\n",
            "steps:  27% 1368/5000 [12:36<33:29,  1.81it/s, loss=0.0449]\n",
            "epoch 115/417\n",
            "steps:  28% 1380/5000 [12:43<33:22,  1.81it/s, loss=0.0644]\n",
            "epoch 116/417\n",
            "steps:  28% 1392/5000 [12:50<33:16,  1.81it/s, loss=0.0655]\n",
            "epoch 117/417\n",
            "steps:  28% 1404/5000 [12:56<33:09,  1.81it/s, loss=0.0716]\n",
            "epoch 118/417\n",
            "steps:  28% 1416/5000 [13:03<33:03,  1.81it/s, loss=0.0987]\n",
            "epoch 119/417\n",
            "steps:  29% 1428/5000 [13:10<32:56,  1.81it/s, loss=0.057] \n",
            "epoch 120/417\n",
            "steps:  29% 1440/5000 [13:16<32:49,  1.81it/s, loss=0.0411]\n",
            "saving checkpoint: output_models/epoch-000120.safetensors\n",
            "\n",
            "epoch 121/417\n",
            "steps:  29% 1452/5000 [13:23<32:43,  1.81it/s, loss=0.091] \n",
            "epoch 122/417\n",
            "steps:  29% 1464/5000 [13:29<32:36,  1.81it/s, loss=0.099] \n",
            "epoch 123/417\n",
            "steps:  30% 1476/5000 [13:36<32:29,  1.81it/s, loss=0.131]\n",
            "epoch 124/417\n",
            "steps:  30% 1488/5000 [13:43<32:22,  1.81it/s, loss=0.0657]\n",
            "epoch 125/417\n",
            "steps:  30% 1500/5000 [13:49<32:15,  1.81it/s, loss=0.0756]\n",
            "epoch 126/417\n",
            "steps:  30% 1512/5000 [13:56<32:09,  1.81it/s, loss=0.0987]\n",
            "epoch 127/417\n",
            "steps:  30% 1524/5000 [14:03<32:03,  1.81it/s, loss=0.0555]\n",
            "epoch 128/417\n",
            "steps:  31% 1536/5000 [14:09<31:56,  1.81it/s, loss=0.112]\n",
            "epoch 129/417\n",
            "steps:  31% 1548/5000 [14:16<31:49,  1.81it/s, loss=0.054] \n",
            "epoch 130/417\n",
            "steps:  31% 1560/5000 [14:23<31:43,  1.81it/s, loss=0.0498]\n",
            "saving checkpoint: output_models/epoch-000130.safetensors\n",
            "\n",
            "epoch 131/417\n",
            "steps:  31% 1572/5000 [14:29<31:37,  1.81it/s, loss=0.123]\n",
            "epoch 132/417\n",
            "steps:  32% 1584/5000 [14:36<31:30,  1.81it/s, loss=0.0486]\n",
            "epoch 133/417\n",
            "steps:  32% 1596/5000 [14:43<31:23,  1.81it/s, loss=0.0933]\n",
            "epoch 134/417\n",
            "steps:  32% 1608/5000 [14:50<31:17,  1.81it/s, loss=0.0934]\n",
            "epoch 135/417\n",
            "steps:  32% 1620/5000 [14:56<31:11,  1.81it/s, loss=0.0519]\n",
            "epoch 136/417\n",
            "steps:  33% 1632/5000 [15:03<31:04,  1.81it/s, loss=0.0789]\n",
            "epoch 137/417\n",
            "steps:  33% 1644/5000 [15:10<30:58,  1.81it/s, loss=0.0625]\n",
            "epoch 138/417\n",
            "steps:  33% 1656/5000 [15:16<30:51,  1.81it/s, loss=0.0905]\n",
            "epoch 139/417\n",
            "steps:  33% 1668/5000 [15:23<30:45,  1.81it/s, loss=0.0472]\n",
            "epoch 140/417\n",
            "steps:  34% 1680/5000 [15:30<30:39,  1.81it/s, loss=0.0743]\n",
            "saving checkpoint: output_models/epoch-000140.safetensors\n",
            "\n",
            "epoch 141/417\n",
            "steps:  34% 1692/5000 [15:37<30:32,  1.80it/s, loss=0.0578]\n",
            "epoch 142/417\n",
            "steps:  34% 1704/5000 [15:44<30:26,  1.80it/s, loss=0.0907]\n",
            "epoch 143/417\n",
            "steps:  34% 1716/5000 [15:51<30:20,  1.80it/s, loss=0.0663]\n",
            "epoch 144/417\n",
            "steps:  35% 1728/5000 [15:57<30:13,  1.80it/s, loss=0.0415]\n",
            "epoch 145/417\n",
            "steps:  35% 1740/5000 [16:04<30:07,  1.80it/s, loss=0.0866]\n",
            "epoch 146/417\n",
            "steps:  35% 1752/5000 [16:11<30:00,  1.80it/s, loss=0.0628]\n",
            "epoch 147/417\n",
            "steps:  35% 1764/5000 [16:18<29:54,  1.80it/s, loss=0.06]  \n",
            "epoch 148/417\n",
            "steps:  36% 1776/5000 [16:25<29:48,  1.80it/s, loss=0.0629]\n",
            "epoch 149/417\n",
            "steps:  36% 1788/5000 [16:31<29:41,  1.80it/s, loss=0.0393]\n",
            "epoch 150/417\n",
            "steps:  36% 1800/5000 [16:38<29:35,  1.80it/s, loss=0.043] \n",
            "saving checkpoint: output_models/epoch-000150.safetensors\n",
            "\n",
            "epoch 151/417\n",
            "steps:  36% 1812/5000 [16:45<29:28,  1.80it/s, loss=0.0576]\n",
            "epoch 152/417\n",
            "steps:  36% 1824/5000 [16:52<29:22,  1.80it/s, loss=0.0745]\n",
            "epoch 153/417\n",
            "steps:  37% 1836/5000 [16:59<29:16,  1.80it/s, loss=0.071] \n",
            "epoch 154/417\n",
            "steps:  37% 1848/5000 [17:05<29:09,  1.80it/s, loss=0.0417]\n",
            "epoch 155/417\n",
            "steps:  37% 1860/5000 [17:12<29:03,  1.80it/s, loss=0.0738]\n",
            "epoch 156/417\n",
            "steps:  37% 1872/5000 [17:19<28:56,  1.80it/s, loss=0.103]\n",
            "epoch 157/417\n",
            "steps:  38% 1884/5000 [17:26<28:50,  1.80it/s, loss=0.0554]\n",
            "epoch 158/417\n",
            "steps:  38% 1896/5000 [17:32<28:43,  1.80it/s, loss=0.0796]\n",
            "epoch 159/417\n",
            "steps:  38% 1908/5000 [17:39<28:36,  1.80it/s, loss=0.0998]\n",
            "epoch 160/417\n",
            "steps:  38% 1920/5000 [17:46<28:30,  1.80it/s, loss=0.0918]\n",
            "saving checkpoint: output_models/epoch-000160.safetensors\n",
            "\n",
            "epoch 161/417\n",
            "steps:  39% 1932/5000 [17:53<28:24,  1.80it/s, loss=0.0378]\n",
            "epoch 162/417\n",
            "steps:  39% 1944/5000 [18:00<28:17,  1.80it/s, loss=0.0978]\n",
            "epoch 163/417\n",
            "steps:  39% 1956/5000 [18:06<28:11,  1.80it/s, loss=0.102] \n",
            "epoch 164/417\n",
            "steps:  39% 1968/5000 [18:13<28:04,  1.80it/s, loss=0.0736]\n",
            "epoch 165/417\n",
            "steps:  40% 1980/5000 [18:20<27:58,  1.80it/s, loss=0.0888]\n",
            "epoch 166/417\n",
            "steps:  40% 1992/5000 [18:27<27:52,  1.80it/s, loss=0.037] \n",
            "epoch 167/417\n",
            "steps:  40% 2004/5000 [18:34<27:45,  1.80it/s, loss=0.0804]\n",
            "epoch 168/417\n",
            "steps:  40% 2016/5000 [18:41<27:39,  1.80it/s, loss=0.0923]\n",
            "epoch 169/417\n",
            "steps:  41% 2028/5000 [18:48<27:33,  1.80it/s, loss=0.0644]\n",
            "epoch 170/417\n",
            "steps:  41% 2040/5000 [18:55<27:27,  1.80it/s, loss=0.0597]\n",
            "saving checkpoint: output_models/epoch-000170.safetensors\n",
            "\n",
            "epoch 171/417\n",
            "steps:  41% 2052/5000 [19:02<27:21,  1.80it/s, loss=0.052] \n",
            "epoch 172/417\n",
            "steps:  41% 2064/5000 [19:08<27:14,  1.80it/s, loss=0.0461]\n",
            "epoch 173/417\n",
            "steps:  42% 2076/5000 [19:15<27:07,  1.80it/s, loss=0.0769]\n",
            "epoch 174/417\n",
            "steps:  42% 2088/5000 [19:22<27:00,  1.80it/s, loss=0.0609]\n",
            "epoch 175/417\n",
            "steps:  42% 2100/5000 [19:28<26:53,  1.80it/s, loss=0.0477]\n",
            "epoch 176/417\n",
            "steps:  42% 2112/5000 [19:35<26:47,  1.80it/s, loss=0.143]\n",
            "epoch 177/417\n",
            "steps:  42% 2124/5000 [19:42<26:40,  1.80it/s, loss=0.0876]\n",
            "epoch 178/417\n",
            "steps:  43% 2136/5000 [19:48<26:33,  1.80it/s, loss=0.0601]\n",
            "epoch 179/417\n",
            "steps:  43% 2148/5000 [19:55<26:27,  1.80it/s, loss=0.0801]\n",
            "epoch 180/417\n",
            "steps:  43% 2160/5000 [20:02<26:20,  1.80it/s, loss=0.0901]\n",
            "saving checkpoint: output_models/epoch-000180.safetensors\n",
            "\n",
            "epoch 181/417\n",
            "steps:  43% 2172/5000 [20:08<26:14,  1.80it/s, loss=0.0915]\n",
            "epoch 182/417\n",
            "steps:  44% 2184/5000 [20:15<26:07,  1.80it/s, loss=0.039] \n",
            "epoch 183/417\n",
            "steps:  44% 2196/5000 [20:22<26:00,  1.80it/s, loss=0.0576]\n",
            "epoch 184/417\n",
            "steps:  44% 2208/5000 [20:28<25:53,  1.80it/s, loss=0.0868]\n",
            "epoch 185/417\n",
            "steps:  44% 2220/5000 [20:35<25:47,  1.80it/s, loss=0.0587]\n",
            "epoch 186/417\n",
            "steps:  45% 2232/5000 [20:42<25:40,  1.80it/s, loss=0.0913]\n",
            "epoch 187/417\n",
            "steps:  45% 2244/5000 [20:48<25:33,  1.80it/s, loss=0.0971]\n",
            "epoch 188/417\n",
            "steps:  45% 2256/5000 [20:55<25:27,  1.80it/s, loss=0.0692]\n",
            "epoch 189/417\n",
            "steps:  45% 2268/5000 [21:02<25:20,  1.80it/s, loss=0.148]\n",
            "epoch 190/417\n",
            "steps:  46% 2280/5000 [21:09<25:13,  1.80it/s, loss=0.0221]\n",
            "saving checkpoint: output_models/epoch-000190.safetensors\n",
            "\n",
            "epoch 191/417\n",
            "steps:  46% 2292/5000 [21:15<25:07,  1.80it/s, loss=0.0641]\n",
            "epoch 192/417\n",
            "steps:  46% 2304/5000 [21:22<25:00,  1.80it/s, loss=0.0599]\n",
            "epoch 193/417\n",
            "steps:  46% 2316/5000 [21:29<24:54,  1.80it/s, loss=0.0342]\n",
            "epoch 194/417\n",
            "steps:  47% 2328/5000 [21:35<24:47,  1.80it/s, loss=0.0514]\n",
            "epoch 195/417\n",
            "steps:  47% 2340/5000 [21:42<24:40,  1.80it/s, loss=0.0666]\n",
            "epoch 196/417\n",
            "steps:  47% 2352/5000 [21:49<24:33,  1.80it/s, loss=0.0904]\n",
            "epoch 197/417\n",
            "steps:  47% 2364/5000 [21:55<24:27,  1.80it/s, loss=0.0599]\n",
            "epoch 198/417\n",
            "steps:  48% 2376/5000 [22:02<24:20,  1.80it/s, loss=0.0519]\n",
            "epoch 199/417\n",
            "steps:  48% 2388/5000 [22:09<24:13,  1.80it/s, loss=0.0988]\n",
            "epoch 200/417\n",
            "steps:  48% 2400/5000 [22:15<24:07,  1.80it/s, loss=0.05]  \n",
            "saving checkpoint: output_models/epoch-000200.safetensors\n",
            "\n",
            "epoch 201/417\n",
            "steps:  48% 2412/5000 [22:22<24:00,  1.80it/s, loss=0.0366]\n",
            "epoch 202/417\n",
            "steps:  48% 2424/5000 [22:29<23:53,  1.80it/s, loss=0.0816]\n",
            "epoch 203/417\n",
            "steps:  49% 2436/5000 [22:36<23:47,  1.80it/s, loss=0.109]\n",
            "epoch 204/417\n",
            "steps:  49% 2448/5000 [22:42<23:40,  1.80it/s, loss=0.0637]\n",
            "epoch 205/417\n",
            "steps:  49% 2460/5000 [22:49<23:33,  1.80it/s, loss=0.0674]\n",
            "epoch 206/417\n",
            "steps:  49% 2472/5000 [22:55<23:26,  1.80it/s, loss=0.0551]\n",
            "epoch 207/417\n",
            "steps:  50% 2484/5000 [23:02<23:20,  1.80it/s, loss=0.0822]\n",
            "epoch 208/417\n",
            "steps:  50% 2496/5000 [23:09<23:13,  1.80it/s, loss=0.0696]\n",
            "epoch 209/417\n",
            "steps:  50% 2508/5000 [23:15<23:06,  1.80it/s, loss=0.0744]\n",
            "epoch 210/417\n",
            "steps:  50% 2520/5000 [23:22<23:00,  1.80it/s, loss=0.0678]\n",
            "saving checkpoint: output_models/epoch-000210.safetensors\n",
            "\n",
            "epoch 211/417\n",
            "steps:  51% 2532/5000 [23:29<22:53,  1.80it/s, loss=0.0415]\n",
            "epoch 212/417\n",
            "steps:  51% 2544/5000 [23:35<22:46,  1.80it/s, loss=0.0455]\n",
            "epoch 213/417\n",
            "steps:  51% 2556/5000 [23:42<22:40,  1.80it/s, loss=0.0921]\n",
            "epoch 214/417\n",
            "steps:  51% 2568/5000 [23:49<22:33,  1.80it/s, loss=0.056] \n",
            "epoch 215/417\n",
            "steps:  52% 2580/5000 [23:55<22:26,  1.80it/s, loss=0.0535]\n",
            "epoch 216/417\n",
            "steps:  52% 2592/5000 [24:02<22:20,  1.80it/s, loss=0.037] \n",
            "epoch 217/417\n",
            "steps:  52% 2604/5000 [24:09<22:13,  1.80it/s, loss=0.0867]\n",
            "epoch 218/417\n",
            "steps:  52% 2616/5000 [24:16<22:06,  1.80it/s, loss=0.0599]\n",
            "epoch 219/417\n",
            "steps:  53% 2628/5000 [24:22<22:00,  1.80it/s, loss=0.0931]\n",
            "epoch 220/417\n",
            "steps:  53% 2640/5000 [24:29<21:53,  1.80it/s, loss=0.0519]\n",
            "saving checkpoint: output_models/epoch-000220.safetensors\n",
            "\n",
            "epoch 221/417\n",
            "steps:  53% 2652/5000 [24:36<21:46,  1.80it/s, loss=0.0601]\n",
            "epoch 222/417\n",
            "steps:  53% 2664/5000 [24:42<21:40,  1.80it/s, loss=0.061] \n",
            "epoch 223/417\n",
            "steps:  54% 2676/5000 [24:49<21:33,  1.80it/s, loss=0.0456]\n",
            "epoch 224/417\n",
            "steps:  54% 2688/5000 [24:56<21:26,  1.80it/s, loss=0.0516]\n",
            "epoch 225/417\n",
            "steps:  54% 2700/5000 [25:02<21:20,  1.80it/s, loss=0.0778]\n",
            "epoch 226/417\n",
            "steps:  54% 2712/5000 [25:09<21:13,  1.80it/s, loss=0.116]\n",
            "epoch 227/417\n",
            "steps:  54% 2724/5000 [25:16<21:06,  1.80it/s, loss=0.0338]\n",
            "epoch 228/417\n",
            "steps:  55% 2736/5000 [25:22<20:59,  1.80it/s, loss=0.0404]\n",
            "epoch 229/417\n",
            "steps:  55% 2748/5000 [25:29<20:53,  1.80it/s, loss=0.086] \n",
            "epoch 230/417\n",
            "steps:  55% 2760/5000 [25:36<20:46,  1.80it/s, loss=0.0655]\n",
            "saving checkpoint: output_models/epoch-000230.safetensors\n",
            "\n",
            "epoch 231/417\n",
            "steps:  55% 2772/5000 [25:42<20:40,  1.80it/s, loss=0.0881]\n",
            "epoch 232/417\n",
            "steps:  56% 2784/5000 [25:49<20:33,  1.80it/s, loss=0.0595]\n",
            "epoch 233/417\n",
            "steps:  56% 2796/5000 [25:56<20:26,  1.80it/s, loss=0.0639]\n",
            "epoch 234/417\n",
            "steps:  56% 2808/5000 [26:03<20:20,  1.80it/s, loss=0.0457]\n",
            "epoch 235/417\n",
            "steps:  56% 2820/5000 [26:10<20:13,  1.80it/s, loss=0.0527]\n",
            "epoch 236/417\n",
            "steps:  57% 2832/5000 [26:16<20:06,  1.80it/s, loss=0.0736]\n",
            "epoch 237/417\n",
            "steps:  57% 2844/5000 [26:23<20:00,  1.80it/s, loss=0.0584]\n",
            "epoch 238/417\n",
            "steps:  57% 2856/5000 [26:30<19:53,  1.80it/s, loss=0.0751]\n",
            "epoch 239/417\n",
            "steps:  57% 2868/5000 [26:36<19:46,  1.80it/s, loss=0.0821]\n",
            "epoch 240/417\n",
            "steps:  58% 2880/5000 [26:43<19:40,  1.80it/s, loss=0.0492]\n",
            "saving checkpoint: output_models/epoch-000240.safetensors\n",
            "\n",
            "epoch 241/417\n",
            "steps:  58% 2892/5000 [26:50<19:33,  1.80it/s, loss=0.148]\n",
            "epoch 242/417\n",
            "steps:  58% 2904/5000 [26:56<19:26,  1.80it/s, loss=0.0542]\n",
            "epoch 243/417\n",
            "steps:  58% 2916/5000 [27:03<19:20,  1.80it/s, loss=0.039] \n",
            "epoch 244/417\n",
            "steps:  59% 2928/5000 [27:09<19:13,  1.80it/s, loss=0.0927]\n",
            "epoch 245/417\n",
            "steps:  59% 2940/5000 [27:16<19:06,  1.80it/s, loss=0.0583]\n",
            "epoch 246/417\n",
            "steps:  59% 2952/5000 [27:23<19:00,  1.80it/s, loss=0.0954]\n",
            "epoch 247/417\n",
            "steps:  59% 2964/5000 [27:29<18:53,  1.80it/s, loss=0.0942]\n",
            "epoch 248/417\n",
            "steps:  60% 2976/5000 [27:36<18:46,  1.80it/s, loss=0.042] \n",
            "epoch 249/417\n",
            "steps:  60% 2988/5000 [27:43<18:39,  1.80it/s, loss=0.0524]\n",
            "epoch 250/417\n",
            "steps:  60% 3000/5000 [27:49<18:33,  1.80it/s, loss=0.0454]\n",
            "saving checkpoint: output_models/epoch-000250.safetensors\n",
            "\n",
            "epoch 251/417\n",
            "steps:  60% 3012/5000 [27:56<18:26,  1.80it/s, loss=0.0935]\n",
            "epoch 252/417\n",
            "steps:  60% 3024/5000 [28:03<18:19,  1.80it/s, loss=0.0697]\n",
            "epoch 253/417\n",
            "steps:  61% 3036/5000 [28:09<18:13,  1.80it/s, loss=0.0572]\n",
            "epoch 254/417\n",
            "steps:  61% 3048/5000 [28:16<18:06,  1.80it/s, loss=0.0845]\n",
            "epoch 255/417\n",
            "steps:  61% 3060/5000 [28:23<17:59,  1.80it/s, loss=0.0586]\n",
            "epoch 256/417\n",
            "steps:  61% 3072/5000 [28:30<17:53,  1.80it/s, loss=0.0456]\n",
            "epoch 257/417\n",
            "steps:  62% 3084/5000 [28:36<17:46,  1.80it/s, loss=0.0623]\n",
            "epoch 258/417\n",
            "steps:  62% 3096/5000 [28:43<17:39,  1.80it/s, loss=0.0794]\n",
            "epoch 259/417\n",
            "steps:  62% 3108/5000 [28:49<17:33,  1.80it/s, loss=0.045] \n",
            "epoch 260/417\n",
            "steps:  62% 3120/5000 [28:56<17:26,  1.80it/s, loss=0.038] \n",
            "saving checkpoint: output_models/epoch-000260.safetensors\n",
            "\n",
            "epoch 261/417\n",
            "steps:  63% 3132/5000 [29:03<17:19,  1.80it/s, loss=0.0857]\n",
            "epoch 262/417\n",
            "steps:  63% 3144/5000 [29:10<17:13,  1.80it/s, loss=0.054] \n",
            "epoch 263/417\n",
            "steps:  63% 3156/5000 [29:16<17:06,  1.80it/s, loss=0.0686]\n",
            "epoch 264/417\n",
            "steps:  63% 3168/5000 [29:23<16:59,  1.80it/s, loss=0.0606]\n",
            "epoch 265/417\n",
            "steps:  64% 3180/5000 [29:29<16:53,  1.80it/s, loss=0.105]\n",
            "epoch 266/417\n",
            "steps:  64% 3192/5000 [29:36<16:46,  1.80it/s, loss=0.0483]\n",
            "epoch 267/417\n",
            "steps:  64% 3204/5000 [29:43<16:39,  1.80it/s, loss=0.0754]\n",
            "epoch 268/417\n",
            "steps:  64% 3216/5000 [29:49<16:32,  1.80it/s, loss=0.0864]\n",
            "epoch 269/417\n",
            "steps:  65% 3228/5000 [29:56<16:26,  1.80it/s, loss=0.052] \n",
            "epoch 270/417\n",
            "steps:  65% 3240/5000 [30:03<16:19,  1.80it/s, loss=0.121]\n",
            "saving checkpoint: output_models/epoch-000270.safetensors\n",
            "\n",
            "epoch 271/417\n",
            "steps:  65% 3252/5000 [30:10<16:13,  1.80it/s, loss=0.0851]\n",
            "epoch 272/417\n",
            "steps:  65% 3264/5000 [30:17<16:06,  1.80it/s, loss=0.0843]\n",
            "epoch 273/417\n",
            "steps:  66% 3276/5000 [30:23<15:59,  1.80it/s, loss=0.0962]\n",
            "epoch 274/417\n",
            "steps:  66% 3288/5000 [30:30<15:53,  1.80it/s, loss=0.0428]\n",
            "epoch 275/417\n",
            "steps:  66% 3300/5000 [30:37<15:46,  1.80it/s, loss=0.0825]\n",
            "epoch 276/417\n",
            "steps:  66% 3312/5000 [30:43<15:39,  1.80it/s, loss=0.0617]\n",
            "epoch 277/417\n",
            "steps:  66% 3324/5000 [30:50<15:33,  1.80it/s, loss=0.104]\n",
            "epoch 278/417\n",
            "steps:  67% 3336/5000 [30:57<15:26,  1.80it/s, loss=0.0432]\n",
            "epoch 279/417\n",
            "steps:  67% 3348/5000 [31:03<15:19,  1.80it/s, loss=0.0642]\n",
            "epoch 280/417\n",
            "steps:  67% 3360/5000 [31:10<15:12,  1.80it/s, loss=0.0628]\n",
            "saving checkpoint: output_models/epoch-000280.safetensors\n",
            "\n",
            "epoch 281/417\n",
            "steps:  67% 3372/5000 [31:17<15:06,  1.80it/s, loss=0.096] \n",
            "epoch 282/417\n",
            "steps:  68% 3384/5000 [31:23<14:59,  1.80it/s, loss=0.0473]\n",
            "epoch 283/417\n",
            "steps:  68% 3396/5000 [31:30<14:53,  1.80it/s, loss=0.0348]\n",
            "epoch 284/417\n",
            "steps:  68% 3408/5000 [31:37<14:46,  1.80it/s, loss=0.06] \n",
            "epoch 285/417\n",
            "steps:  68% 3420/5000 [31:44<14:39,  1.80it/s, loss=0.0547]\n",
            "epoch 286/417\n",
            "steps:  69% 3432/5000 [31:50<14:32,  1.80it/s, loss=0.0341]\n",
            "epoch 287/417\n",
            "steps:  69% 3444/5000 [31:57<14:26,  1.80it/s, loss=0.0858]\n",
            "epoch 288/417\n",
            "steps:  69% 3456/5000 [32:04<14:19,  1.80it/s, loss=0.0425]\n",
            "epoch 289/417\n",
            "steps:  69% 3468/5000 [32:10<14:12,  1.80it/s, loss=0.0749]\n",
            "epoch 290/417\n",
            "steps:  70% 3480/5000 [32:17<14:06,  1.80it/s, loss=0.108]\n",
            "saving checkpoint: output_models/epoch-000290.safetensors\n",
            "\n",
            "epoch 291/417\n",
            "steps:  70% 3492/5000 [32:24<13:59,  1.80it/s, loss=0.0616]\n",
            "epoch 292/417\n",
            "steps:  70% 3504/5000 [32:31<13:52,  1.80it/s, loss=0.0578]\n",
            "epoch 293/417\n",
            "steps:  70% 3516/5000 [32:37<13:46,  1.80it/s, loss=0.0577]\n",
            "epoch 294/417\n",
            "steps:  71% 3528/5000 [32:44<13:39,  1.80it/s, loss=0.0485]\n",
            "epoch 295/417\n",
            "steps:  71% 3540/5000 [32:51<13:32,  1.80it/s, loss=0.0561]\n",
            "epoch 296/417\n",
            "steps:  71% 3552/5000 [32:58<13:26,  1.80it/s, loss=0.0938]\n",
            "epoch 297/417\n",
            "steps:  71% 3564/5000 [33:04<13:19,  1.80it/s, loss=0.119]\n",
            "epoch 298/417\n",
            "steps:  72% 3576/5000 [33:11<13:12,  1.80it/s, loss=0.0447]\n",
            "epoch 299/417\n",
            "steps:  72% 3588/5000 [33:18<13:06,  1.80it/s, loss=0.0922]\n",
            "epoch 300/417\n",
            "steps:  72% 3600/5000 [33:24<12:59,  1.80it/s, loss=0.0644]\n",
            "saving checkpoint: output_models/epoch-000300.safetensors\n",
            "\n",
            "epoch 301/417\n",
            "steps:  72% 3612/5000 [33:31<12:53,  1.80it/s, loss=0.0681]\n",
            "epoch 302/417\n",
            "steps:  72% 3624/5000 [33:38<12:46,  1.80it/s, loss=0.0303]\n",
            "epoch 303/417\n",
            "steps:  73% 3636/5000 [33:44<12:39,  1.80it/s, loss=0.0802]\n",
            "epoch 304/417\n",
            "steps:  73% 3648/5000 [33:51<12:32,  1.80it/s, loss=0.0475]\n",
            "epoch 305/417\n",
            "steps:  73% 3660/5000 [33:58<12:26,  1.80it/s, loss=0.0893]\n",
            "epoch 306/417\n",
            "steps:  73% 3672/5000 [34:05<12:19,  1.80it/s, loss=0.0647]\n",
            "epoch 307/417\n",
            "steps:  74% 3684/5000 [34:11<12:13,  1.80it/s, loss=0.0991]\n",
            "epoch 308/417\n",
            "steps:  74% 3696/5000 [34:18<12:06,  1.80it/s, loss=0.0616]\n",
            "epoch 309/417\n",
            "steps:  74% 3708/5000 [34:25<11:59,  1.80it/s, loss=0.0695]\n",
            "epoch 310/417\n",
            "steps:  74% 3720/5000 [34:32<11:52,  1.80it/s, loss=0.0595]\n",
            "saving checkpoint: output_models/epoch-000310.safetensors\n",
            "\n",
            "epoch 311/417\n",
            "steps:  75% 3732/5000 [34:39<11:46,  1.80it/s, loss=0.0608]\n",
            "epoch 312/417\n",
            "steps:  75% 3744/5000 [34:45<11:39,  1.79it/s, loss=0.0872]\n",
            "epoch 313/417\n",
            "steps:  75% 3756/5000 [34:52<11:33,  1.80it/s, loss=0.0714]\n",
            "epoch 314/417\n",
            "steps:  75% 3768/5000 [34:59<11:26,  1.79it/s, loss=0.0408]\n",
            "epoch 315/417\n",
            "steps:  76% 3780/5000 [35:05<11:19,  1.79it/s, loss=0.0459]\n",
            "epoch 316/417\n",
            "steps:  76% 3792/5000 [35:12<11:12,  1.79it/s, loss=0.0687]\n",
            "epoch 317/417\n",
            "steps:  76% 3804/5000 [35:19<11:06,  1.79it/s, loss=0.0632]\n",
            "epoch 318/417\n",
            "steps:  76% 3816/5000 [35:25<10:59,  1.79it/s, loss=0.0347]\n",
            "epoch 319/417\n",
            "steps:  77% 3828/5000 [35:32<10:52,  1.79it/s, loss=0.054] \n",
            "epoch 320/417\n",
            "steps:  77% 3840/5000 [35:39<10:46,  1.79it/s, loss=0.0529]\n",
            "saving checkpoint: output_models/epoch-000320.safetensors\n",
            "\n",
            "epoch 321/417\n",
            "steps:  77% 3852/5000 [35:46<10:39,  1.79it/s, loss=0.059] \n",
            "epoch 322/417\n",
            "steps:  77% 3864/5000 [35:52<10:32,  1.79it/s, loss=0.0705]\n",
            "epoch 323/417\n",
            "steps:  78% 3876/5000 [35:59<10:26,  1.79it/s, loss=0.0848]\n",
            "epoch 324/417\n",
            "steps:  78% 3888/5000 [36:06<10:19,  1.79it/s, loss=0.0695]\n",
            "epoch 325/417\n",
            "steps:  78% 3900/5000 [36:12<10:12,  1.79it/s, loss=0.0677]\n",
            "epoch 326/417\n",
            "steps:  78% 3912/5000 [36:19<10:06,  1.80it/s, loss=0.0579]\n",
            "epoch 327/417\n",
            "steps:  78% 3924/5000 [36:25<09:59,  1.80it/s, loss=0.0201]\n",
            "epoch 328/417\n",
            "steps:  79% 3936/5000 [36:32<09:52,  1.79it/s, loss=0.0614]\n",
            "epoch 329/417\n",
            "steps:  79% 3948/5000 [36:39<09:46,  1.79it/s, loss=0.0799]\n",
            "epoch 330/417\n",
            "steps:  79% 3960/5000 [36:46<09:39,  1.79it/s, loss=0.0942]\n",
            "saving checkpoint: output_models/epoch-000330.safetensors\n",
            "\n",
            "epoch 331/417\n",
            "steps:  79% 3972/5000 [36:52<09:32,  1.79it/s, loss=0.0657]\n",
            "epoch 332/417\n",
            "steps:  80% 3984/5000 [36:59<09:26,  1.79it/s, loss=0.0825]\n",
            "epoch 333/417\n",
            "steps:  80% 3996/5000 [37:06<09:19,  1.79it/s, loss=0.0564]\n",
            "epoch 334/417\n",
            "steps:  80% 4008/5000 [37:12<09:12,  1.80it/s, loss=0.0815]\n",
            "epoch 335/417\n",
            "steps:  80% 4020/5000 [37:19<09:05,  1.80it/s, loss=0.0775]\n",
            "epoch 336/417\n",
            "steps:  81% 4032/5000 [37:26<08:59,  1.80it/s, loss=0.044] \n",
            "epoch 337/417\n",
            "steps:  81% 4044/5000 [37:32<08:52,  1.80it/s, loss=0.063] \n",
            "epoch 338/417\n",
            "steps:  81% 4056/5000 [37:39<08:45,  1.80it/s, loss=0.0989]\n",
            "epoch 339/417\n",
            "steps:  81% 4068/5000 [37:45<08:39,  1.80it/s, loss=0.0584]\n",
            "epoch 340/417\n",
            "steps:  82% 4080/5000 [37:52<08:32,  1.80it/s, loss=0.11] \n",
            "saving checkpoint: output_models/epoch-000340.safetensors\n",
            "\n",
            "epoch 341/417\n",
            "steps:  82% 4092/5000 [37:59<08:25,  1.80it/s, loss=0.169]\n",
            "epoch 342/417\n",
            "steps:  82% 4104/5000 [38:05<08:19,  1.80it/s, loss=0.0471]\n",
            "epoch 343/417\n",
            "steps:  82% 4116/5000 [38:12<08:12,  1.80it/s, loss=0.0797]\n",
            "epoch 344/417\n",
            "steps:  83% 4128/5000 [38:19<08:05,  1.80it/s, loss=0.0375]\n",
            "epoch 345/417\n",
            "steps:  83% 4140/5000 [38:25<07:58,  1.80it/s, loss=0.0489]\n",
            "epoch 346/417\n",
            "steps:  83% 4152/5000 [38:32<07:52,  1.80it/s, loss=0.0664]\n",
            "epoch 347/417\n",
            "steps:  83% 4164/5000 [38:38<07:45,  1.80it/s, loss=0.0739]\n",
            "epoch 348/417\n",
            "steps:  84% 4176/5000 [38:45<07:38,  1.80it/s, loss=0.0839]\n",
            "epoch 349/417\n",
            "steps:  84% 4188/5000 [38:52<07:32,  1.80it/s, loss=0.0693]\n",
            "epoch 350/417\n",
            "steps:  84% 4200/5000 [38:58<07:25,  1.80it/s, loss=0.0282]\n",
            "saving checkpoint: output_models/epoch-000350.safetensors\n",
            "\n",
            "epoch 351/417\n",
            "steps:  84% 4212/5000 [39:05<07:18,  1.80it/s, loss=0.0882]\n",
            "epoch 352/417\n",
            "steps:  84% 4224/5000 [39:12<07:12,  1.80it/s, loss=0.0285]\n",
            "epoch 353/417\n",
            "steps:  85% 4236/5000 [39:18<07:05,  1.80it/s, loss=0.0746]\n",
            "epoch 354/417\n",
            "steps:  85% 4248/5000 [39:25<06:58,  1.80it/s, loss=0.0478]\n",
            "epoch 355/417\n",
            "steps:  85% 4260/5000 [39:31<06:51,  1.80it/s, loss=0.0484]\n",
            "epoch 356/417\n",
            "steps:  85% 4272/5000 [39:38<06:45,  1.80it/s, loss=0.139]\n",
            "epoch 357/417\n",
            "steps:  86% 4284/5000 [39:44<06:38,  1.80it/s, loss=0.0615]\n",
            "epoch 358/417\n",
            "steps:  86% 4296/5000 [39:51<06:31,  1.80it/s, loss=0.0475]\n",
            "epoch 359/417\n",
            "steps:  86% 4308/5000 [39:58<06:25,  1.80it/s, loss=0.0675]\n",
            "epoch 360/417\n",
            "steps:  86% 4320/5000 [40:04<06:18,  1.80it/s, loss=0.0553]\n",
            "saving checkpoint: output_models/epoch-000360.safetensors\n",
            "\n",
            "epoch 361/417\n",
            "steps:  87% 4332/5000 [40:11<06:11,  1.80it/s, loss=0.0529]\n",
            "epoch 362/417\n",
            "steps:  87% 4344/5000 [40:18<06:05,  1.80it/s, loss=0.0232]\n",
            "epoch 363/417\n",
            "steps:  87% 4356/5000 [40:24<05:58,  1.80it/s, loss=0.0866]\n",
            "epoch 364/417\n",
            "steps:  87% 4368/5000 [40:31<05:51,  1.80it/s, loss=0.0605]\n",
            "epoch 365/417\n",
            "steps:  88% 4380/5000 [40:38<05:45,  1.80it/s, loss=0.0638]\n",
            "epoch 366/417\n",
            "steps:  88% 4392/5000 [40:45<05:38,  1.80it/s, loss=0.0538]\n",
            "epoch 367/417\n",
            "steps:  88% 4404/5000 [40:52<05:31,  1.80it/s, loss=0.0565]\n",
            "epoch 368/417\n",
            "steps:  88% 4416/5000 [40:59<05:25,  1.80it/s, loss=0.0623]\n",
            "epoch 369/417\n",
            "steps:  89% 4428/5000 [41:05<05:18,  1.80it/s, loss=0.043] \n",
            "epoch 370/417\n",
            "steps:  89% 4440/5000 [41:12<05:11,  1.80it/s, loss=0.0649]\n",
            "saving checkpoint: output_models/epoch-000370.safetensors\n",
            "\n",
            "epoch 371/417\n",
            "steps:  89% 4452/5000 [41:19<05:05,  1.80it/s, loss=0.0613]\n",
            "epoch 372/417\n",
            "steps:  89% 4464/5000 [41:26<04:58,  1.80it/s, loss=0.044] \n",
            "epoch 373/417\n",
            "steps:  90% 4476/5000 [41:32<04:51,  1.80it/s, loss=0.0564]\n",
            "epoch 374/417\n",
            "steps:  90% 4488/5000 [41:39<04:45,  1.80it/s, loss=0.0862]\n",
            "epoch 375/417\n",
            "steps:  90% 4500/5000 [41:46<04:38,  1.80it/s, loss=0.0597]\n",
            "epoch 376/417\n",
            "steps:  90% 4512/5000 [41:52<04:31,  1.80it/s, loss=0.0481]\n",
            "epoch 377/417\n",
            "steps:  90% 4524/5000 [41:59<04:25,  1.80it/s, loss=0.0961]\n",
            "epoch 378/417\n",
            "steps:  91% 4536/5000 [42:06<04:18,  1.80it/s, loss=0.0694]\n",
            "epoch 379/417\n",
            "steps:  91% 4548/5000 [42:13<04:11,  1.80it/s, loss=0.0444]\n",
            "epoch 380/417\n",
            "steps:  91% 4560/5000 [42:20<04:05,  1.80it/s, loss=0.0802]\n",
            "saving checkpoint: output_models/epoch-000380.safetensors\n",
            "\n",
            "epoch 381/417\n",
            "steps:  91% 4572/5000 [42:27<03:58,  1.79it/s, loss=0.0737]\n",
            "epoch 382/417\n",
            "steps:  92% 4584/5000 [42:33<03:51,  1.80it/s, loss=0.0743]\n",
            "epoch 383/417\n",
            "steps:  92% 4596/5000 [42:40<03:45,  1.79it/s, loss=0.0521]\n",
            "epoch 384/417\n",
            "steps:  92% 4608/5000 [42:47<03:38,  1.79it/s, loss=0.0935]\n",
            "epoch 385/417\n",
            "steps:  92% 4620/5000 [42:54<03:31,  1.79it/s, loss=0.0321]\n",
            "epoch 386/417\n",
            "steps:  93% 4632/5000 [43:00<03:25,  1.79it/s, loss=0.0468]\n",
            "epoch 387/417\n",
            "steps:  93% 4644/5000 [43:07<03:18,  1.79it/s, loss=0.0658]\n",
            "epoch 388/417\n",
            "steps:  93% 4656/5000 [43:14<03:11,  1.79it/s, loss=0.0462]\n",
            "epoch 389/417\n",
            "steps:  93% 4668/5000 [43:20<03:04,  1.79it/s, loss=0.025] \n",
            "epoch 390/417\n",
            "steps:  94% 4680/5000 [43:27<02:58,  1.79it/s, loss=0.0369]\n",
            "saving checkpoint: output_models/epoch-000390.safetensors\n",
            "\n",
            "epoch 391/417\n",
            "steps:  94% 4692/5000 [43:34<02:51,  1.79it/s, loss=0.0593]\n",
            "epoch 392/417\n",
            "steps:  94% 4704/5000 [43:40<02:44,  1.79it/s, loss=0.0501]\n",
            "epoch 393/417\n",
            "steps:  94% 4716/5000 [43:47<02:38,  1.79it/s, loss=0.0384]\n",
            "epoch 394/417\n",
            "steps:  95% 4728/5000 [43:53<02:31,  1.79it/s, loss=0.0481]\n",
            "epoch 395/417\n",
            "steps:  95% 4740/5000 [44:00<02:24,  1.80it/s, loss=0.107]\n",
            "epoch 396/417\n",
            "steps:  95% 4752/5000 [44:07<02:18,  1.80it/s, loss=0.0562]\n",
            "epoch 397/417\n",
            "steps:  95% 4764/5000 [44:13<02:11,  1.80it/s, loss=0.0454]\n",
            "epoch 398/417\n",
            "steps:  96% 4776/5000 [44:20<02:04,  1.80it/s, loss=0.062]\n",
            "epoch 399/417\n",
            "steps:  96% 4788/5000 [44:27<01:58,  1.79it/s, loss=0.0782]\n",
            "epoch 400/417\n",
            "steps:  96% 4800/5000 [44:34<01:51,  1.79it/s, loss=0.0567]\n",
            "saving checkpoint: output_models/epoch-000400.safetensors\n",
            "\n",
            "epoch 401/417\n",
            "steps:  96% 4812/5000 [44:40<01:44,  1.79it/s, loss=0.0646]\n",
            "epoch 402/417\n",
            "steps:  96% 4824/5000 [44:47<01:38,  1.79it/s, loss=0.0628]\n",
            "epoch 403/417\n",
            "steps:  97% 4836/5000 [44:54<01:31,  1.80it/s, loss=0.0313]\n",
            "epoch 404/417\n",
            "steps:  97% 4848/5000 [45:00<01:24,  1.79it/s, loss=0.0937]\n",
            "epoch 405/417\n",
            "steps:  97% 4860/5000 [45:07<01:17,  1.79it/s, loss=0.0703]\n",
            "epoch 406/417\n",
            "steps:  97% 4872/5000 [45:14<01:11,  1.80it/s, loss=0.113]\n",
            "epoch 407/417\n",
            "steps:  98% 4884/5000 [45:21<01:04,  1.79it/s, loss=0.0607]\n",
            "epoch 408/417\n",
            "steps:  98% 4896/5000 [45:27<00:57,  1.79it/s, loss=0.0607]\n",
            "epoch 409/417\n",
            "steps:  98% 4908/5000 [45:34<00:51,  1.79it/s, loss=0.0997]\n",
            "epoch 410/417\n",
            "steps:  98% 4920/5000 [45:40<00:44,  1.79it/s, loss=0.0574]\n",
            "saving checkpoint: output_models/epoch-000410.safetensors\n",
            "\n",
            "epoch 411/417\n",
            "steps:  99% 4932/5000 [45:47<00:37,  1.79it/s, loss=0.0395]\n",
            "epoch 412/417\n",
            "steps:  99% 4944/5000 [45:54<00:31,  1.79it/s, loss=0.0813]\n",
            "epoch 413/417\n",
            "steps:  99% 4956/5000 [46:01<00:24,  1.79it/s, loss=0.0697]\n",
            "epoch 414/417\n",
            "steps:  99% 4968/5000 [46:07<00:17,  1.80it/s, loss=0.0418]\n",
            "epoch 415/417\n",
            "steps: 100% 4980/5000 [46:14<00:11,  1.79it/s, loss=0.0514]\n",
            "epoch 416/417\n",
            "steps: 100% 4992/5000 [46:20<00:04,  1.80it/s, loss=0.048] \n",
            "epoch 417/417\n",
            "steps: 100% 5000/5000 [46:25<00:00,  1.80it/s, loss=0.0511]\n",
            "saving checkpoint: output_models/last.safetensors\n",
            "model saved.\n",
            "steps: 100% 5000/5000 [46:25<00:00,  1.79it/s, loss=0.0511]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='/content/drive/MyDrive/StableDifussion/sd-scripts/output_models/last.safetensors'\n",
        "save_path='/content/drive/MyDrive/my_models/canbright_satoo/'\n",
        "new_file_name = 'satoo_without_descriptions_5000.safetensors'\n",
        "\n",
        "!mkdir -p '{save_path}'\n",
        "!cp '{model_path}' '{save_path}/{new_file_name}'"
      ],
      "metadata": {
        "id": "pJexKL2dINlj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/StableDifussion/sd-scripts/gen_img_diffusers.py \\\n",
        "  --ckpt /content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt \\\n",
        "  --n_iter 1 \\\n",
        "  --scale 7.5 \\\n",
        "  --steps 20 \\\n",
        "  --outdir /content  \\\n",
        "  --prompt \"a boy,((((cb_satoo))))\" \\\n",
        "  --xformers \\\n",
        "  --W 512 \\\n",
        "  --H 512 \\\n",
        "  --seed   1 \\\n",
        "  --sampler k_euler_a \\\n",
        "  --network_module networks.lora \\\n",
        "  --network_weights /content/drive/MyDrive/my_models/canbright_satoo/satoo_with_descriptions_10000.safetensors \\\n",
        "  --network_mul 1 \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --clip_skip 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --images_per_prompt 1 \n",
        "  #--bf16 \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqyHn1K9INjr",
        "outputId": "fa323bd5-25a6-4811-f956-9fab80a4e69e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-13 10:21:09.987688: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-13 10:21:10.192986: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-13 10:21:10.983118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:21:10.983201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-13 10:21:10.983217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "CrossAttention.forward has been replaced to enable xformers and NAI style Hypernetwork\n",
            "Use Diffusers xformers for VAE\n",
            "loading tokenizer\n",
            "prepare tokenizer\n",
            "import network module: networks.lora\n",
            "load network weights from: /content/drive/MyDrive/my_models/canbright_satoo/satoo_with_descriptions_10000.safetensors\n",
            "create LoRA network from weights\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "weights are loaded: <All keys matched successfully>\n",
            "pipeline is ready.\n",
            "iteration 1/1\n",
            "prompt 1/1: a boy,((((cb_satoo))))\n",
            "100% 20/20 [00:10<00:00,  1.94it/s]\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# *for test: remove \"caption\" and \"tags\" \n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/meta_lat.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for key in data:\n",
        "    if \"caption\" in data[key]:\n",
        "        del data[key][\"caption\"]\n",
        "    if \"tags\" in data[key]:\n",
        "        del data[key][\"tags\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/modified_meta_lat.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "YQTSkHycMEu3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THndNz_-MEmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNSJkOlkINfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV9YQqDXRImk"
      },
      "outputs": [],
      "source": [
        "# write dataset config\n",
        "import toml\n",
        "instance_data_dir='/content/drive/MyDrive/datasets/imgs/with_txt_resized_canbright_imgs_1_partial/'\n",
        "\n",
        "dataset_config={\n",
        "    'general': {\n",
        "        'enable_bucket': True\n",
        "    },\n",
        "    'datasets': [\n",
        "        {\n",
        "            'resolution': 512,\n",
        "            'batch_size': 4,\n",
        "            'subsets': [\n",
        "                {\n",
        "                    'image_dir': instance_data_dir,\n",
        "                    'caption_extension': '.txt',\n",
        "                    'num_repeats': 1\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "dataset_config_path='/content/drive/MyDrive/ML_Practices/Lora_test_1/lora/dataset_config.toml'\n",
        "with open(dataset_config_path, 'w') as file:\n",
        "    toml.dump(dataset_config, file)"
      ]
    }
  ]
}