{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1BFg3Z87hRxmiWr8jmGOhnElZt3iD0IaA",
      "authorship_tag": "ABX9TyNlmSM7BXmAM87NZAfQFUQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nekoiii/ML_Practices_colab/blob/main/Lora_test_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sd-scripts github: https://github.com/kohya-ss/sd-scripts\n",
        "\n",
        "Reference article：\n",
        "· https://tkstock.site/2023/05/19/googlecolab-stablediffusion-lora-finetuning/#i-7\n",
        "\n",
        "· https://www.ipentec.com/document/software-stable-diffusion-lora-learn#section_12\n",
        "\n"
      ],
      "metadata": {
        "id": "3oxQHizixLE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aShyASAL7AIv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd_path='/content/drive/MyDrive/StableDifussion/sd-scripts'\n",
        "#lora_path=\n",
        "pretrained_model_name_or_path='/content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt'\n"
      ],
      "metadata": {
        "id": "xF1YZZ79Yl_Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone sd-script\n",
        "%%script false --no-raise-error\n",
        "%%capture\n",
        "!git clone https://github.com/kohya-ss/sd-scripts '{sd_path}'"
      ],
      "metadata": {
        "id": "YIK3xuD87MXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install sd-script Requirements\n",
        "\n",
        "#According to the sd-scripts github documentation, we should install PyTorch before install requirements.txt \n",
        "#because the versions of it depends on your environment and requirements.txt does not contain requirements for PyTorch.\n",
        "\n",
        "#%%capture\n",
        "\n",
        "%cd '{sd_path}'\n",
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install  --upgrade -r requirements.txt\n",
        "#!pip install -U --pre triton\n",
        "!pip install xformers==0.0.16rc425\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iIbzKkG67MU7",
        "outputId": "5bd33053-3ea0-42d6-dca4-2c99ad4287cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch==1.13.1+cu117 in /usr/local/lib/python3.10/dist-packages (1.13.1+cu117)\n",
            "Requirement already satisfied: torchvision==0.14.1+cu117 in /usr/local/lib/python3.10/dist-packages (0.14.1+cu117)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu117) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/StableDifussion/sd-scripts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.15.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1 (from -r requirements.txt (line 3))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations==1.3.0 (from -r requirements.txt (line 4))\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.7.0.68 (from -r requirements.txt (line 5))\n",
            "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.0 (from -r requirements.txt (line 6))\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers[torch]==0.10.2 (from -r requirements.txt (line 7))\n",
            "  Downloading diffusers-0.10.2-py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.35.0 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.35.0-py3-none-any.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard==2.10.1 (from -r requirements.txt (line 10))\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors==0.2.6 (from -r requirements.txt (line 11))\n",
            "  Downloading safetensors-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.2.2)\n",
            "Collecting easygui==0.98.3 (from -r requirements.txt (line 14))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Collecting voluptuous==0.13.1 (from -r requirements.txt (line 16))\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Collecting requests==2.28.2 (from -r requirements.txt (line 18))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.6.12 (from -r requirements.txt (line 19))\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale==0.4.13 (from -r requirements.txt (line 20))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow==2.10.1 (from -r requirements.txt (line 23))\n",
            "  Downloading tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.13.3 (from -r requirements.txt (line 24))\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.15.0->-r requirements.txt (line 1)) (1.13.1+cu117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.0->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.0->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 3)) (0.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->-r requirements.txt (line 4)) (4.7.0.72)\n",
            "Collecting importlib-metadata (from diffusers[torch]==0.10.2->-r requirements.txt (line 7))\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.5.0)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (3.4.3)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (67.7.2)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard==2.10.1->-r requirements.txt (line 10))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.10.1->-r requirements.txt (line 10)) (0.40.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (4.3.3)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (1.5.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.txt (line 13)) (0.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->-r requirements.txt (line 18)) (2022.12.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12->-r requirements.txt (line 19)) (0.14.1+cu117)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.8.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 23))\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 23)) (1.14.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 13)) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 13)) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 13)) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[torch]==0.10.2->-r requirements.txt (line 7)) (3.15.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.1->-r requirements.txt (line 10)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.1->-r requirements.txt (line 10)) (3.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Building wheels for collected packages: fairscale, library\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=7b8384f32562aa61bfa57a32f5d937c12ae095892669d3bc783edf031e71091e\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for library: filename=library-0.0.0-py3-none-any.whl size=83355 sha256=9e5d51f23ece5720ed958ece3be4a6cd4ac5a5ebfacd434dae8b49e94bcde3f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/56/d6/9784fb87ab54c1caf203d81a063041071e9705a7c313678e4d\n",
            "Successfully built fairscale library\n",
            "Installing collected packages: voluptuous, tokenizers, safetensors, library, keras, easygui, bitsandbytes, tensorflow-estimator, tensorboard-data-server, requests, protobuf, opencv-python, multidict, lightning-utilities, keras-preprocessing, importlib-metadata, ftfy, frozenlist, einops, async-timeout, yarl, torchmetrics, huggingface-hub, fairscale, aiosignal, accelerate, transformers, timm, google-auth-oauthlib, diffusers, aiohttp, tensorboard, albumentations, tensorflow, pytorch-lightning\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.7.0.72\n",
            "    Uninstalling opencv-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-4.7.0.72\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.15.0 aiohttp-3.8.4 aiosignal-1.3.1 albumentations-1.3.0 async-timeout-4.0.2 bitsandbytes-0.35.0 diffusers-0.10.2 easygui-0.98.3 einops-0.6.0 fairscale-0.4.13 frozenlist-1.3.3 ftfy-6.1.1 google-auth-oauthlib-0.4.6 huggingface-hub-0.13.3 importlib-metadata-6.6.0 keras-2.10.0 keras-preprocessing-1.1.2 library-0.0.0 lightning-utilities-0.8.0 multidict-6.0.4 opencv-python-4.7.0.68 protobuf-3.19.6 pytorch-lightning-1.9.0 requests-2.28.2 safetensors-0.2.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 timm-0.6.12 tokenizers-0.13.3 torchmetrics-0.11.4 transformers-4.26.0 voluptuous-0.13.1 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xformers==0.0.16rc425 in /usr/local/lib/python3.10/dist-packages (0.0.16rc425)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (1.22.4)\n",
            "Requirement already satisfied: pyre-extensions==0.0.23 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (0.0.23)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.16rc425) (1.13.1+cu117)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.23->xformers==0.0.16rc425) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.23->xformers==0.0.16rc425) (4.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.23->xformers==0.0.16rc425) (1.0.0)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use fp16\n",
        "\n",
        "# Change some config (Some user reports [ValueError: fp16 mixed precision requires a GPU] is occurred in training )\n",
        "\n",
        "%%capture\n",
        "\n",
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "id": "Y0UPKQip-IXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy Training Images Folder\n",
        "training_data_path='/content/training_data'\n",
        "original_data_path='/content/drive/MyDrive/datasets/imgs/resized_canbright_imgs_1_partial'\n",
        "\n",
        "%cp -r '{original_data_path}' '{training_data_path}'"
      ],
      "metadata": {
        "id": "xtp4ZN6f-IVD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate captions and tags for each image.\n",
        "%%capture\n",
        "\n",
        "%cd '{sd_path}'\n",
        "\n",
        "!python finetune/make_captions.py --batch_size 8 '{training_data_path}'\n",
        "!python finetune/tag_images_by_wd14_tagger.py --batch_size 4 '{training_data_path}'"
      ],
      "metadata": {
        "id": "9duevbKj-IRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Descriptions For Images\n",
        "\n",
        "# Merges captions with metadata and outputs the result in meta_cap.json.\n",
        "# Merges Data Description (DD) tags with metadata from the previous step and generates a new file meta_cap_dd.json.\n",
        "# Cleans and preprocesses the captions and tags from the previous step and generates a cleaned version in meta_clean.json.\n",
        "\n",
        "%%capture\n",
        "\n",
        "!python finetune/merge_captions_to_metadata.py '{training_data_path}' meta_cap.json\n",
        "!python finetune/merge_dd_tags_to_metadata.py '{training_data_path}' --in_json meta_cap.json meta_cap_dd.json\n",
        "!python finetune/clean_captions_and_tags.py meta_cap_dd.json meta_clean.json"
      ],
      "metadata": {
        "id": "mTqoRfiH_89C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "\n",
        "!python finetune/prepare_buckets_latents.py \\\n",
        "'{training_data_path}' meta_clean.json meta_lat.json \\\n",
        "'{pretrained_model_name_or_path}' \\\n",
        "--batch_size 4 \\\n",
        "--max_resolution 512,512 \\\n",
        "--mixed_precision no"
      ],
      "metadata": {
        "id": "CpeipJV2_86a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgGDs2bG1K-",
        "outputId": "1308b979-2d58-49c8-aa0d-e347ec6a06c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sd-scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_network.py: https://github.com/kohya-ss/sd-scripts/blob/main/train_network.py\n",
        "\n",
        "!accelerate launch  \\\n",
        "--num_cpu_threads_per_process 1 \\\n",
        "train_network.py \\\n",
        "--pretrained_model_name_or_path='{pretrained_model_name_or_path}' \\\n",
        "--in_json modified_meta_lat.json \\\n",
        "--train_data_dir='{training_data_path}' \\\n",
        "--output_dir=output_models \\\n",
        "--shuffle_caption \\\n",
        "--train_batch_size=1 \\\n",
        "--learning_rate=1e-4 \\\n",
        "--max_train_steps=500 \\\n",
        "--use_8bit_adam \\\n",
        "--xformers --gradient_checkpointing \\\n",
        "--mixed_precision=fp16 \\\n",
        "--save_every_n_epochs=10 \\\n",
        "--save_precision=fp16 \\\n",
        "--network_module=networks.lora\\\n",
        "--training_comment=\"cb_satoo\" \\\n",
        "#--save_model_as= safetensors\n",
        "#--save_model_as= pt \n",
        "#--output_name=satoo_with_descriptions \\\n"
      ],
      "metadata": {
        "id": "tsVo9HXx7MLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_model_path='/content/drive/MyDrive/StableDifussion/sd-scripts/output_models/last.safetensors'\n",
        "save_path='/content/drive/MyDrive/my_models/canbright_satoo/'\n",
        "new_file_name = 'satoo_without_descriptions_5000.safetensors'\n",
        "\n",
        "!mkdir -p '{save_path}'\n",
        "!cp '{output_model_path}' '{save_path}/{new_file_name}'"
      ],
      "metadata": {
        "id": "pJexKL2dINlj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/kohya-ss/sd-scripts/blob/main/gen_img_diffusers.py\n",
        "\n",
        "used_model='/content/drive/MyDrive/my_models/canbright_satoo/satoo_with_descriptions_10000.safetensors'\n",
        "steps=20\n",
        "seed=1\n",
        "prompt='a boy,((((cb_satoo))))'\n",
        "\n",
        "outdir='/content/output_imgs/'\n",
        "\n",
        "!python /content/drive/MyDrive/StableDifussion/sd-scripts/gen_img_diffusers.py \\\n",
        "  --ckpt '{pretrained_model_name_or_path}' \\\n",
        "  --n_iter 1 \\\n",
        "  --scale 7.5 \\\n",
        "  --steps '{steps}' \\\n",
        "  --outdir  '{outdir}' \\\n",
        "  --prompt '{prompt}' \\\n",
        "  --xformers \\\n",
        "  --W 512 \\\n",
        "  --H 512 \\\n",
        "  --seed  '{seed}' \\\n",
        "  --sampler k_euler_a \\\n",
        "  --network_module networks.lora \\\n",
        "  --network_weights  '{used_model}' \\\n",
        "  --network_mul 1 \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --clip_skip 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --images_per_prompt 1 \n",
        "  #--bf16 \\\n",
        "  #--seed   1 \\"
      ],
      "metadata": {
        "id": "QqyHn1K9INjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *for test: remove \"caption\" and \"tags\" \n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/meta_lat.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for key in data:\n",
        "    if \"caption\" in data[key]:\n",
        "        del data[key][\"caption\"]\n",
        "    if \"tags\" in data[key]:\n",
        "        del data[key][\"tags\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/modified_meta_lat.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "YQTSkHycMEu3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THndNz_-MEmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNSJkOlkINfZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}