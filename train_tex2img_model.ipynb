{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1BFg3Z87hRxmiWr8jmGOhnElZt3iD0IaA",
      "authorship_tag": "ABX9TyO3EpwvdUY1ao3SxIXv+bLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nekoiii/ML_Practices_colab/blob/main/train_tex2img_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sd-scripts github: https://github.com/kohya-ss/sd-scripts\n",
        "\n",
        "Reference article：\n",
        "· https://tkstock.site/2023/05/19/googlecolab-stablediffusion-lora-finetuning/#i-7\n",
        "\n",
        "· https://www.ipentec.com/document/software-stable-diffusion-lora-learn#section_12\n",
        "\n"
      ],
      "metadata": {
        "id": "3oxQHizixLE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aShyASAL7AIv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd_path='/content/drive/MyDrive/StableDifussion/sd-scripts'\n",
        "#lora_path=\n",
        "pretrained_model_name_or_path='/content/drive/MyDrive/StableDifussion/models/anything-v4.5-pruned-fp16.ckpt'\n"
      ],
      "metadata": {
        "id": "xF1YZZ79Yl_Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone sd-script\n",
        "%%script false --no-raise-error\n",
        "%%capture\n",
        "!git clone https://github.com/kohya-ss/sd-scripts '{sd_path}'"
      ],
      "metadata": {
        "id": "YIK3xuD87MXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install sd-script Requirements\n",
        "\n",
        "#According to the sd-scripts github documentation, we should install PyTorch before install requirements.txt \n",
        "#because the versions of it depends on your environment and requirements.txt does not contain requirements for PyTorch.\n",
        "\n",
        "#%%capture\n",
        "\n",
        "%cd '{sd_path}'\n",
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install  --upgrade -r requirements.txt\n",
        "#!pip install -U --pre triton\n",
        "!pip install xformers==0.0.16rc425\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "iIbzKkG67MU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use fp16\n",
        "\n",
        "# Change some config (Some user reports [ValueError: fp16 mixed precision requires a GPU] is occurred in training )\n",
        "\n",
        "%%capture\n",
        "\n",
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "id": "Y0UPKQip-IXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy Training Images Folder\n",
        "training_data_path='/content/training_data'\n",
        "original_data_path='/content/drive/MyDrive/datasets/imgs/resized_canbright_imgs_1_partial'\n",
        "\n",
        "%cp -r '{original_data_path}' '{training_data_path}'"
      ],
      "metadata": {
        "id": "xtp4ZN6f-IVD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate captions and tags for each image.\n",
        "%%capture\n",
        "\n",
        "%cd '{sd_path}'\n",
        "\n",
        "!python finetune/make_captions.py --batch_size 8 '{training_data_path}'\n",
        "!python finetune/tag_images_by_wd14_tagger.py --batch_size 4 '{training_data_path}'"
      ],
      "metadata": {
        "id": "9duevbKj-IRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Descriptions For Images\n",
        "\n",
        "# Merges captions with metadata and outputs the result in meta_cap.json.\n",
        "# Merges Data Description (DD) tags with metadata from the previous step and generates a new file meta_cap_dd.json.\n",
        "# Cleans and preprocesses the captions and tags from the previous step and generates a cleaned version in meta_clean.json.\n",
        "\n",
        "%%capture\n",
        "\n",
        "!python finetune/merge_captions_to_metadata.py '{training_data_path}' meta_cap.json\n",
        "!python finetune/merge_dd_tags_to_metadata.py '{training_data_path}' --in_json meta_cap.json meta_cap_dd.json\n",
        "!python finetune/clean_captions_and_tags.py meta_cap_dd.json meta_clean.json"
      ],
      "metadata": {
        "id": "mTqoRfiH_89C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "\n",
        "!python finetune/prepare_buckets_latents.py \\\n",
        "'{training_data_path}' meta_clean.json meta_lat.json \\\n",
        "'{pretrained_model_name_or_path}' \\\n",
        "--batch_size 4 \\\n",
        "--max_resolution 512,512 \\\n",
        "--mixed_precision no"
      ],
      "metadata": {
        "id": "CpeipJV2_86a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgGDs2bG1K-",
        "outputId": "1308b979-2d58-49c8-aa0d-e347ec6a06c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sd-scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_network.py: https://github.com/kohya-ss/sd-scripts/blob/main/train_network.py\n",
        "\n",
        "!accelerate launch  \\\n",
        "--num_cpu_threads_per_process 1 \\\n",
        "train_network.py \\\n",
        "--pretrained_model_name_or_path='{pretrained_model_name_or_path}' \\\n",
        "--in_json modified_meta_lat.json \\\n",
        "--train_data_dir='{training_data_path}' \\\n",
        "--output_dir=output_models \\\n",
        "--shuffle_caption \\\n",
        "--train_batch_size=1 \\\n",
        "--learning_rate=1e-4 \\\n",
        "--max_train_steps=500 \\\n",
        "--use_8bit_adam \\\n",
        "--xformers --gradient_checkpointing \\\n",
        "--mixed_precision=fp16 \\\n",
        "--save_every_n_epochs=10 \\\n",
        "--save_precision=fp16 \\\n",
        "--network_module=networks.lora\\\n",
        "--training_comment=\"cb_satoo\" \\\n",
        "#--save_model_as= safetensors\n",
        "#--save_model_as= pt \n",
        "#--output_name=satoo_with_descriptions \\\n"
      ],
      "metadata": {
        "id": "tsVo9HXx7MLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_model_path='/content/drive/MyDrive/StableDifussion/sd-scripts/output_models/last.safetensors'\n",
        "save_path='/content/drive/MyDrive/my_models/canbright_satoo/'\n",
        "new_file_name = 'satoo_without_descriptions_5000.safetensors'\n",
        "\n",
        "!mkdir -p '{save_path}'\n",
        "!cp '{output_model_path}' '{save_path}/{new_file_name}'"
      ],
      "metadata": {
        "id": "pJexKL2dINlj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/kohya-ss/sd-scripts/blob/main/gen_img_diffusers.py\n",
        "\n",
        "used_model='/content/drive/MyDrive/my_models/canbright_satoo/satoo_with_descriptions_10000.safetensors'\n",
        "steps=20\n",
        "seed=1\n",
        "prompt='a boy hoding a milk,((((cb_satoo))))'\n",
        "\n",
        "outdir='/content/output_imgs/'\n",
        "\n",
        "!python /content/drive/MyDrive/StableDifussion/sd-scripts/gen_img_diffusers.py \\\n",
        "  --ckpt '{pretrained_model_name_or_path}' \\\n",
        "  --n_iter 1 \\\n",
        "  --scale 7.5 \\\n",
        "  --steps '{steps}' \\\n",
        "  --outdir  '{outdir}' \\\n",
        "  --prompt '{prompt}' \\\n",
        "  --xformers \\\n",
        "  --W 512 \\\n",
        "  --H 512 \\\n",
        "  --seed  '{seed}' \\\n",
        "  --sampler k_euler_a \\\n",
        "  --network_module networks.lora \\\n",
        "  --network_weights  '{used_model}' \\\n",
        "  --network_mul 1 \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --clip_skip 1 \\\n",
        "  --batch_size 1 \\\n",
        "  --images_per_prompt 1 \n",
        "  #--bf16 \\\n",
        "  #--seed   1 \\"
      ],
      "metadata": {
        "id": "QqyHn1K9INjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *for test: remove \"caption\" and \"tags\" \n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/meta_lat.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for key in data:\n",
        "    if \"caption\" in data[key]:\n",
        "        del data[key][\"caption\"]\n",
        "    if \"tags\" in data[key]:\n",
        "        del data[key][\"tags\"]\n",
        "\n",
        "with open('/content/drive/MyDrive/StableDifussion/sd-scripts/modified_meta_lat.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "YQTSkHycMEu3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THndNz_-MEmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNSJkOlkINfZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}