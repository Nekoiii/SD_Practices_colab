{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1IAMVAgLXNBiQ-jcTh5oAnlbQv0yNXmrZ",
      "authorship_tag": "ABX9TyNy6X5B9ohnD5ybVSLCM0tz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nekoiii/ML_Practices_colab/blob/main/Rola_test_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考文章：https://note.com/npaka/n/ndb287a48b682"
      ],
      "metadata": {
        "id": "xXzCp16iBqyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6ck3pSFj_EBS"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/ML_Practices/Lora_test_1'\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp5kyV7I_26a",
        "outputId": "a9770b78-7ff8-49e4-eead-aaf8154bc1ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_Practices/Lora_test_1\n",
            "/content/drive/MyDrive/ML_Practices/Lora_test_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download Lora\n",
        "%cd  /content/drive/MyDrive/StableDifussion/Lora\n",
        "!git clone https://github.com/cloneofsimo/lora.git\n",
        "\n",
        "!pip install accelerate bitsandbytes\n",
        "!pip install -r requirements.txt\n",
        "#%cd lora\n",
        "#!pip install .\n",
        "!pwd"
      ],
      "metadata": {
        "id": "-p0obTIeAb6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824c482e-87fa-4a17-f71d-ae64515f1d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/StableDifussion/Lora'\n",
            "/content/drive/MyDrive/ML_Practices/Lora_test_1\n",
            "Cloning into 'lora'...\n",
            "remote: Enumerating objects: 934, done.\u001b[K\n",
            "remote: Counting objects: 100% (407/407), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 934 (delta 346), reused 301 (delta 301), pack-reused 527\u001b[K\n",
            "Receiving objects: 100% (934/934), 182.96 MiB | 26.44 MiB/s, done.\n",
            "Resolving deltas: 100% (560/560), done.\n",
            "Updating files: 100% (60/60), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.20.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考文章：https://torch.classcat.com/2023/04/12/blog-sd-webui-colab-lora-training-by-diffusers/"
      ],
      "metadata": {
        "id": "xx0xMDGPVmaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.14.0 transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "OAXBMd3-Fkbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers.git -b v0.14.0"
      ],
      "metadata": {
        "id": "YAGCR4RBFkw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "\n",
        "write_basic_config(mixed_precision=\"fp16\", save_location=\"/content/lora/default_config.yaml\")\n",
        "!cat /content/lora/default_config.yaml"
      ],
      "metadata": {
        "id": "5-HB5Z8jVsLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/lora/default_config.yaml"
      ],
      "metadata": {
        "id": "G-eKNAlUVsTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!accelerate launch --config_file=\"/content/lora/default_config.yaml\" \\\n",
        "  /content/drive/MyDrive/ML_Practices/Lora_test_1/diffusers/examples/dreambooth/train_dreambooth_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\"  \\\n",
        "  --instance_data_dir=\"/content/drive/MyDrive/ML_Practices/Lora_test_1/resized_sample_data_3\" \\\n",
        "  --output_dir=\"/content/lora/output\" \\\n",
        "  --instance_prompt=\"shs\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --sample_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --checkpointing_steps=200 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --seed=\"0\""
      ],
      "metadata": {
        "id": "Jo_bCgVAVsYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16,\n",
        "    ).to('cuda')\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
      ],
      "metadata": {
        "id": "afNU9QylVshb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "fIxFfHR6a2he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.unet.load_attn_procs(\"/content/lora/output/pytorch_lora_weights.bin\")"
      ],
      "metadata": {
        "id": "jXzk6Xy4cUqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generator = [torch.Generator(device=\"cpu\").manual_seed(i) for i in range(4)]\n",
        "\n",
        "images = pipe(prompt=\" (((shs))),1 girl,cute ,simple,happy,computer,business,white background,pure background,sticker\",\n",
        "              negative_prompt=\"authentic,real people,complicated,grey\",\n",
        "              #generator=generator,\n",
        "              num_inference_steps=30,\n",
        "              height=512,\n",
        "              width=512,\n",
        "              num_images_per_prompt=4,\n",
        "              guidance_scale=7.0).images\n",
        "\n",
        "image_grid(images, 2, 2)"
      ],
      "metadata": {
        "id": "XsszFyVKa3Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPOJvstLa3eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8pdaT8jFk1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6qFRKiaFk9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}